{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas import Series,DataFrame\n",
    "import re\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "#寻找小区对应的区域和建造年份\n",
    "def get_data(x):\n",
    "    try:\n",
    "        html=requests.get('https://dl.lianjia.com/xiaoqu/rs'+x)\n",
    "        soup=BeautifulSoup(html.text,'lxml')\n",
    "        s=soup.select('.info .title a')\n",
    "        for i in range(0,len(s)):\n",
    "            if s[i].string==x:\n",
    "                district=soup.select('.info .positionInfo .district')[i].string\n",
    "                bizcircle=soup.select('.info .positionInfo .bizcircle')[i].string\n",
    "                temp=soup.select('.info .positionInfo')[i].get_text()\n",
    "                nianfen=re.search('\\d+',temp).group()\n",
    "                return x+' '+district+' '+bizcircle+' '+ str(nianfen)\n",
    "        else:\n",
    "            return None\n",
    "    except IndexError as e:\n",
    "        print(x)\n",
    "\n",
    "pd.set_option('display.max_rows',None)\n",
    "# #设置显示全部列，不省略\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "item=[]\n",
    "for line in open('data/lianjia.json','r',encoding='utf-8'):\n",
    "    item.append(json.loads(line))\n",
    "    \n",
    "df=DataFrame(item)\n",
    "df.drop_duplicates(inplace=True)\n",
    "#把车位这一行删掉\n",
    "df.drop(index=df[df['area']=='车位'].index,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getarea=lambda x: float(re.search(r\"\\d+(\\.\\d+)?\",x).group())\n",
    "df['area']=df['area'].apply(getarea)\n",
    "tofloat=lambda x:float(x)\n",
    "df['unitPrice']=df['unitPrice'].apply(tofloat)\n",
    "df['totalPrice']=df['totalPrice'].apply(tofloat)\n",
    "df['dealDate']=pd.to_datetime(df['dealDate'])\n",
    "df['dealCycle']=df['dealCycle'].map(lambda x:int(re.search('\\d+',x).group()))\n",
    "df['guaPai']=df['guaPai'].apply(getarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出降价幅度大的房子\n",
    "f=df[((df['guaPai']-df['totalPrice'])/df['guaPai']>0.05) & (df['dealDate'].map(lambda x:x.year)==2021)].sort_values(by=['title','dealDate'])\n",
    "f['chazhi']=round((f['guaPai']-f['totalPrice'])/f['guaPai'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出各个销售的销售量，目前看工人村单个销售卖的还真多\n",
    "s=df.groupby(['seller'])[['seller']].count()\n",
    "s.index.name='num'\n",
    "s.sort_values(by=['seller'],ascending=False)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#找出各小区的销售数量，先忽略时间\n",
    "# xiaoqu=df.groupby(['title'])[['title']].count()\n",
    "xiaoqu=df['title'].groupby([df['title'],df['dealDate'].apply(lambda x:x.year)]).count()\n",
    "xiaoqu.index.names=['title','year']\n",
    "result=list(set(list(map(lambda x:re.search('悦泰(\\w+)?',x),xiaoqu.index.levels[0]))))\n",
    "result.remove(None)\n",
    "r=[i.group() for i in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=xiaoqu.loc[r[1]]\n",
    "s2=xiaoqu.loc[r[0]]\n",
    "s1.name=r[1]\n",
    "s2.name=r[0]\n",
    "print(s1,s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出某个小区的销售情况\n",
    "print(get_data('第五郡五号地'))\n",
    "df_wu=df[df['title'].apply(lambda x: '第五郡' in x and '公寓' not in x)]\n",
    "df_wu=df_wu.sort_values(by='dealDate')\n",
    "df_wu=df_wu.reset_index(drop=True)\n",
    "func=lambda x:str((x.year)*100+(x.month))[0:4]+'-'+str((x.year)*100+(x.month))[4:]\n",
    "df_wu['month']=df_wu['dealDate'].map(func)\n",
    "df_wu['title'].groupby(df_wu['month']).count()\n",
    "# df[df['title']=='金海花园西园'][['title']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出小区每年均价，按月标本太少，不太准确\n",
    "df_wu['unitPrice'].groupby(df_wu['dealDate'].map(lambda x:x.year)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出小区的成交周期\n",
    "df_wu['dealCycle'].groupby(df_wu['dealDate'].apply(lambda x:x.year)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#找出房子里只有一天成交周期的房子\n",
    "df[(df['dealCycle'].map(lambda x:x==1)) & (df['dealDate'].apply(lambda x:x.year)==2021)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#备用功能        \n",
    "# list=[]\n",
    "# for i in df['title'].drop_duplicates():\n",
    "#     g=get_data(i)\n",
    "#     if g is not None:\n",
    "#         list.append(g)\n",
    "\n",
    "# %run main.py\n",
    "#df.to_json(path_or_buf='data/test.json',orient='index',force_ascii=False)\n",
    "#检查area数据\n",
    "# for i in range(0,len(df)):\n",
    "#     result=df.iloc[i]\n",
    "#     if re.search(r'\\d+(\\.\\d+)?(平米)',result[2]) is None:\n",
    "#         print(df.iloc[i])\n",
    "#         df.drop([i])\n",
    "# #检查挂牌数据\n",
    "# for i in range(0,len(df)):\n",
    "#     result=df.iloc[i]\n",
    "#     if re.search('挂牌*',result[7]) is None:\n",
    "#         print(str(i))\n",
    "        # df.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据已有数据算全部小区\n",
    "dd=df['unitPrice'].groupby(df['dealDate'].apply(lambda x:x.year)).describe()\n",
    "dd[dd.index>2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas import DataFrame\n",
    "# def get_xiaoqu(n1, n2):\n",
    "list = []\n",
    "for line in open('data/lianjia.json', 'r', encoding='utf-8'):\n",
    "    list.append(json.loads(line))\n",
    "\n",
    "\n",
    "df = DataFrame(list)  \n",
    "l=[x for x in df['title']]\n",
    "s=[x for x in set(l) if x is not None]\n",
    "s.sort()\n",
    "item = s[0:1]\n",
    "# return item\n",
    "\n",
    "# get_xiaoqu(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-7dea00d7764c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mspider_lianjia\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspiders\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchengjiao\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mget_chengjiao_one\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mg\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mget_chengjiao_one\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_chengjiao\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'悦泰福里'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\python\\python\\爬虫\\spider_lianjia\\spider_lianjia\\spiders\\chengjiao.py\u001B[0m in \u001B[0;36mget_chengjiao\u001B[1;34m(self, s)\u001B[0m\n\u001B[0;32m    122\u001B[0m             \u001B[0mseller\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_seller\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0metree\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mHTML\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrequests\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 124\u001B[1;33m             \u001B[0mtitle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"//div[@class='wrapper']/text()\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    125\u001B[0m             \u001B[0mroom\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"//div[@class='wrapper']/text()\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    126\u001B[0m             \u001B[0marea\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresponse\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxpath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"//div[@class='wrapper']/text()\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from spider_lianjia.spiders.chengjiao import get_chengjiao_one\n",
    "g=get_chengjiao_one()\n",
    "g.get_chengjiao('悦泰福里')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}